**開發計畫：**

2. **結構規劃**

   - 建立 `crawler.js` 負責主要的爬蟲邏輯
   - 建立 `utils/fileHandler.js` 負責寫檔與路徑處理
   - 使用 playwright 來瀏覽網頁並且抓取超連結
   - 遞迴地抓取每個超連結的內容
   - 儲存抓取到的網頁為 html 檔案，並且放到 output 資料夾中

3. **爬蟲流程**

   - 進入首頁，抓取所有 `<a>` 標籤的 `href`
   - 遞迴/Queue 方式依序拜訪下一層網頁
   - 每抓到一頁，使用 `page.content()` 取得 HTML，並儲存成對應檔名

4. **監控與避免重複**

   - 設計資料結構（如 Set 或 Map）記錄已拜訪連結
   - 確保不重複抓取同網址

5. **測試與驗證**
   - 測試能成功抓下指定網站所有頁面
   - 確認產生的 HTML 檔案內容完整
